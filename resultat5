# Utilisation de l'oversampling pour équilibrer l'échantillon de données pour que la machine puisse entraine sur ce type de données et fournis des résultats correctes,
#
#
# Par le méthode ADASYN  #############################################################################################################

PS C:\Users\Admin\Desktop\projet lamih 2> & "c:/Users/Admin/Desktop/projet lamih 2/myenv/Scripts/python.exe" "c:/Users/Admin/Desktop/projet lamih 2/classification.py"
(68, 13)
(18, 13)
C:\Users\Admin\Desktop\projet lamih 2\myenv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[ True  True  True  True False False  True  True  True  True  True False
 False  True False False  True  True]
75     True
0      True
70     True
22    False
12     True
56    False
10     True
18    False
4     False
67    False
61    False
64    False
53    False
73     True
62    False
66    False
33     True
78    False
Name: labelm, dtype: bool
              precision    recall  f1-score   support

       False       0.83      0.45      0.59        11
        True       0.50      0.86      0.63         7

    accuracy                           0.61        18
   macro avg       0.67      0.66      0.61        18
weighted avg       0.70      0.61      0.61        18

0.6111111111111112



# Par la méthode SMOTE (Synthetic Minority Oversampling Technique) ################################################################

PS C:\Users\Admin\Desktop\projet lamih 2> & "c:/Users/Admin/Desktop/projet lamih 2/myenv/Scripts/python.exe" "c:/Users/Admin/Desktop/projet lamih 2/classification.py"
(68, 13)
(18, 13)
C:\Users\Admin\Desktop\projet lamih 2\myenv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[ True  True  True  True False False  True  True  True  True  True False
 False  True False False  True  True]
75     True
0      True
70     True
22    False
12     True
56    False
10     True
18    False
4     False
67    False
61    False
64    False
53    False
73     True
62    False
66    False
33     True
78    False
Name: labelm, dtype: bool
              precision    recall  f1-score   support

       False       0.83      0.45      0.59        11
        True       0.50      0.86      0.63         7

    accuracy                           0.61        18
   macro avg       0.67      0.66      0.61        18
weighted avg       0.70      0.61      0.61        18

0.6111111111111112

# Par une duplication simple ######################################################################################################

PS C:\Users\Admin\Desktop\projet lamih 2> & "c:/Users/Admin/Desktop/projet lamih 2/myenv/Scripts/python.exe" "c:/Users/Admin/Desktop/projet lamih 2/classification.py"
(86, 13)
(22, 13)
C:\Users\Admin\Desktop\projet lamih 2\myenv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1): 
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
[False False False False  True False False  True  True  True  True  True
  True  True False  True  True  True  True  True False  True]
40     True
21    False
15    False
71     True
10     True
14     True
55    False
77    False
74     True
22    False
1      True
73     True
4     False
9      True
43    False
37     True
72     True
1      True
35     True
67    False
23    False
61    False
Name: labelm, dtype: bool
              precision    recall  f1-score   support

       False       0.62      0.50      0.56        10
        True       0.64      0.75      0.69        12

    accuracy                           0.64        22
   macro avg       0.63      0.62      0.62        22
weighted avg       0.63      0.64      0.63        22

0.6363636363636364
